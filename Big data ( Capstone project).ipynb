{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Create a SparkSession\n",
        "spark = SparkSession.builder.appName(\"MySparkApp\").getOrCreate()\n",
        "\n",
        "filepath = \"/content/st_scores.csv\"\n",
        "\n",
        "#read the raw CSV file - a spark DataFrame\n",
        "raw_stdata = spark.read.format(\"csv\") \\\n",
        "                      .option(\"inferSchema\", \"true\") \\\n",
        "                      .option(\"header\", \"true\") \\\n",
        "                      .load(filepath) \\\n",
        "                      .withColumnRenamed(\"Class Score\",\"ClassScore\") \\\n",
        "                      .withColumnRenamed(\"Test Score\",\"TestScore\")\n",
        "\n",
        "#checking schema - ensuring whether everything is gone good or not\n",
        "raw_stdata.printSchema()\n",
        "\n",
        "#checking data\n",
        "raw_stdata.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Mpylpt_UB4A",
        "outputId": "382a8d87-9307-4faa-f9f1-3bb71d4e2790"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Student: string (nullable = true)\n",
            " |-- Subject: string (nullable = true)\n",
            " |-- ClassScore: integer (nullable = true)\n",
            " |-- TestScore: double (nullable = true)\n",
            "\n",
            "+-------+---------+----------+---------+\n",
            "|Student|  Subject|ClassScore|TestScore|\n",
            "+-------+---------+----------+---------+\n",
            "|  James|     Math|        95|   65.175|\n",
            "|  James|Chemistry|        50|    32.45|\n",
            "|  James|  Physics|        48|   37.675|\n",
            "|  James|  Biology|        75|   76.725|\n",
            "|   Lora|     Math|        45|   49.225|\n",
            "+-------+---------+----------+---------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "source": [
        "fileout = \"/content/partitioned_st\" # Changed to a local path\n",
        "\n",
        "raw_stdata.write \\\n",
        "          .format(\"parquet\") \\\n",
        "          .mode(\"overwrite\") \\\n",
        "          .option(\"compression\", \"gzip\") \\\n",
        "          .partitionBy(\"Subject\") \\\n",
        "          .save(fileout)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "MakCaH8OWEsV"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "st_data = spark.read.parquet(fileout)\n",
        "\n",
        "print(\"# of partitions in dataset : \" + str(st_data.rdd.getNumPartitions()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1_TtlblWNJ2",
        "outputId": "38c0a0c8-ccb5-450c-ad4e-9c564632dc70"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# of partitions in dataset : 2\n"
          ]
        }
      ]
    },
    {
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import functions as F # Import functions module\n",
        "\n",
        "# ... your existing code ...\n",
        "\n",
        "tot_score = st_data.withColumn(\"TotScore\",\n",
        "                        F.col(\"ClassScore\") # Use F.col to refer to columns\n",
        "                        + F.col(\"TestScore\"))\n",
        "\n",
        "tot_score.show(5)\n",
        "\n",
        "print(\"--------Explain--------\")\n",
        "tot_score.explain() # Call explain as a function\n",
        "print(\"--------End of Explain--------\")\n",
        "print(\"# of partitions in dataset : \" + str(tot_score.rdd.getNumPartitions())) # Convert to string"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhCdVhw0Wp5t",
        "outputId": "eaf03c43-9d3a-4a38-9c46-c343c916caa5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------+---------+-------+--------+\n",
            "|Student|ClassScore|TestScore|Subject|TotScore|\n",
            "+-------+----------+---------+-------+--------+\n",
            "|  James|        95|   65.175|   Math| 160.175|\n",
            "|   Lora|        45|   49.225|   Math|  94.225|\n",
            "|   Leny|        36|   65.175|   Math| 101.175|\n",
            "|   Lisa|        33|    78.65|   Math|  111.65|\n",
            "|  Elvis|        27|     33.0|   Math|    60.0|\n",
            "+-------+----------+---------+-------+--------+\n",
            "only showing top 5 rows\n",
            "\n",
            "--------Explain--------\n",
            "== Physical Plan ==\n",
            "*(1) Project [Student#74, ClassScore#75, TestScore#76, Subject#77, (cast(ClassScore#75 as double) + TestScore#76) AS TotScore#82]\n",
            "+- *(1) ColumnarToRow\n",
            "   +- FileScan parquet [Student#74,ClassScore#75,TestScore#76,Subject#77] Batched: true, DataFilters: [], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/content/partitioned_st], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<Student:string,ClassScore:int,TestScore:double>\n",
            "\n",
            "\n",
            "--------End of Explain--------\n",
            "# of partitions in dataset : 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "physics_score = tot_score.filter(tot_score[\"Subject\"] == \"Physics\")\n",
        "\n",
        "physics_score.show()\n",
        "\n",
        "print(\"--------Explain--------\")\n",
        "physics_score.explain\n",
        "print(\"--------End of Explain--------\")\n",
        "print(\"# of partitions in dataset : \" , physics_score.rdd.getNumPartitions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlmhaDfAWx0d",
        "outputId": "6ddcd894-cc24-4958-dda1-22348c6d66e2"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+----------+---------+-------+---------+\n",
            "|Student|ClassScore|TestScore|Subject| TotScore|\n",
            "+-------+----------+---------+-------+---------+\n",
            "|  James|        48|   37.675|Physics|   85.675|\n",
            "|   Lora|        34|     74.8|Physics|    108.8|\n",
            "|   Leny|        93|   79.475|Physics|  172.475|\n",
            "|   Lisa|        42|    64.35|Physics|   106.35|\n",
            "|  Elvis|        82|     77.0|Physics|    159.0|\n",
            "|Micheal|        48| 31.68125|Physics| 79.68125|\n",
            "| Daniel|        34|     62.9|Physics|     96.9|\n",
            "|   Dave|        93| 66.83125|Physics|159.83125|\n",
            "|   Roby|        42|  54.1125|Physics|  96.1125|\n",
            "| Pamela|        82|    64.75|Physics|   146.75|\n",
            "+-------+----------+---------+-------+---------+\n",
            "\n",
            "--------Explain--------\n",
            "--------End of Explain--------\n",
            "# of partitions in dataset :  <bound method RDD.getNumPartitions of MapPartitionsRDD[55] at javaToPython at NativeMethodAccessorImpl.java:0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "avgscore = tot_score.groupBy(\"Student\").avg(\"TotScore\")\n",
        "\n",
        "avgscore.show()\n",
        "\n",
        "print(\"--------Explain--------\")\n",
        "avgscore.explain\n",
        "print(\"--------End of Explain--------\")\n",
        "print(\"# of partitions in dataset : \" , avgscore.rdd.getNumPartitions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jgR-ix6W-nw",
        "outputId": "1acb61db-7944-48cb-87d4-616a69dc993b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------------+\n",
            "|Student|     avg(TotScore)|\n",
            "+-------+------------------+\n",
            "|  James|         120.00625|\n",
            "|   Dave|       121.0359375|\n",
            "|  Elvis|113.60624999999999|\n",
            "| Pamela|       103.2484375|\n",
            "|   Lora| 99.23124999999999|\n",
            "|   Roby|         89.478125|\n",
            "|   Leny|         131.30625|\n",
            "| Daniel| 90.40468750000001|\n",
            "|Micheal|115.45625000000001|\n",
            "|   Lisa| 97.98750000000001|\n",
            "+-------+------------------+\n",
            "\n",
            "--------Explain--------\n",
            "--------End of Explain--------\n",
            "# of partitions in dataset :  <bound method RDD.getNumPartitions of MapPartitionsRDD[78] at javaToPython at NativeMethodAccessorImpl.java:0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, max\n",
        "\n",
        "# finding top score\n",
        "top = tot_score.groupBy(\"Subject\").agg(max(\"TotScore\").alias(\"Tops\"))\n",
        "top.show()\n",
        "\n",
        "# sorting out the students with top scores\n",
        "top_student = tot_score.alias(\"t1\").join(top.alias(\"t2\"),\n",
        "                                         (col(\"t2.Tops\") == col(\"t1.TotScore\")) & (col(\"t2.Subject\") == col(\"t1.Subject\"))) \\\n",
        "    .select(\"t1.Subject\", \"t1.Student\", \"t2.Tops\")\n",
        "top_student.show()\n",
        "\n",
        "print(\"--------Explain--------\")\n",
        "top_student.explain()\n",
        "print(\"--------End of Explain--------\")\n",
        "print(\"# of partitions in dataset:\", top_student.rdd.getNumPartitions())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KB39rfAPXMO6",
        "outputId": "dfbd5690-b81d-4390-d5a8-8984b6c6a044"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-------+\n",
            "|  Subject|   Tops|\n",
            "+---------+-------+\n",
            "|     Math|160.175|\n",
            "|  Biology|151.725|\n",
            "|Chemistry| 120.65|\n",
            "|  Physics|172.475|\n",
            "+---------+-------+\n",
            "\n",
            "+---------+-------+-------+\n",
            "|  Subject|Student|   Tops|\n",
            "+---------+-------+-------+\n",
            "|     Math|  James|160.175|\n",
            "|     Math|Micheal|160.175|\n",
            "|  Biology|  James|151.725|\n",
            "|  Physics|   Leny|172.475|\n",
            "|Chemistry|   Leny| 120.65|\n",
            "+---------+-------+-------+\n",
            "\n",
            "--------Explain--------\n",
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=false\n",
            "+- Project [Subject#77, Student#74, Tops#214]\n",
            "   +- BroadcastHashJoin [knownfloatingpointnormalized(normalizenanandzero(TotScore#82)), Subject#77], [knownfloatingpointnormalized(normalizenanandzero(Tops#214)), Subject#233], Inner, BuildRight, false\n",
            "      :- Project [Student#74, Subject#77, (cast(ClassScore#75 as double) + TestScore#76) AS TotScore#82]\n",
            "      :  +- Filter isnotnull((cast(ClassScore#75 as double) + TestScore#76))\n",
            "      :     +- FileScan parquet [Student#74,ClassScore#75,TestScore#76,Subject#77] Batched: true, DataFilters: [isnotnull((cast(ClassScore#75 as double) + TestScore#76))], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/content/partitioned_st], PartitionFilters: [isnotnull(Subject#77)], PushedFilters: [], ReadSchema: struct<Student:string,ClassScore:int,TestScore:double>\n",
            "      +- BroadcastExchange HashedRelationBroadcastMode(List(knownfloatingpointnormalized(normalizenanandzero(input[1, double, false])), input[0, string, true]),false), [plan_id=549]\n",
            "         +- Filter isnotnull(Tops#214)\n",
            "            +- HashAggregate(keys=[Subject#233], functions=[max(TotScore#82)])\n",
            "               +- Exchange hashpartitioning(Subject#233, 200), ENSURE_REQUIREMENTS, [plan_id=545]\n",
            "                  +- HashAggregate(keys=[Subject#233], functions=[partial_max(TotScore#82)])\n",
            "                     +- Project [Subject#233, (cast(ClassScore#231 as double) + TestScore#232) AS TotScore#82]\n",
            "                        +- FileScan parquet [ClassScore#231,TestScore#232,Subject#233] Batched: true, DataFilters: [], Format: Parquet, Location: InMemoryFileIndex(1 paths)[file:/content/partitioned_st], PartitionFilters: [isnotnull(Subject#233)], PushedFilters: [], ReadSchema: struct<ClassScore:int,TestScore:double>\n",
            "\n",
            "\n",
            "--------End of Explain--------\n",
            "# of partitions in dataset: 2\n"
          ]
        }
      ]
    }
  ]
}